{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n halo untuk pendaftaran bisa via whatsapp atau harus datang kesana \\n siang ka mau tanya kalau untuk tes pre marital apa aja ya dan biaya nya di berapa\\n pak  bu maaf bisa tanya biaya oprasi ga buat oprasi tiroid  makasih\\n mau tnya kl biaya treadmill brp ya \\n saya peserta bpjs apakah bisa ke dr nia  hari rabu tgl 28 juni'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import ast\n",
    "\n",
    "sentence = \"\"\"\n",
    "1. Halo. Untuk pendaftaran bisa via WhatsApp atau harus datang kesana y?\n",
    "2. Siang ka. Mau tanya kalau untuk tes pre marital apa aja ya? Dan biaya nya di berapa?\n",
    "3. Pak / bu maaf bisa tanya biaya oprasi ga buat oprasi tiroid ? makasihhhhhh\n",
    "4. Mau tnya kl biaya treadmill brp ya ?\n",
    "5. Saya peserta bpjs apakah bisa ke dr nia  hari rabu tgl 28 juni\"\"\"\n",
    "\n",
    "sentence = sentence.translate(str.maketrans('','',string.punctuation)) #to remove the punctuation\n",
    "sentence = re.sub(r'([^aeiou\\s])\\1{2,}|([aeiou])\\2{2,}', r'\\1\\2', sentence) #to remove the words that contain too much consonant\n",
    "sentence = re.sub(r'\\b\\w{1}\\b', '', sentence) #to remove number each line\n",
    "sentence = sentence.lower() #to make all letter lowercase\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['halo',\n",
       " 'untuk',\n",
       " 'pendaftaran',\n",
       " 'bisa',\n",
       " 'via',\n",
       " 'whatsapp',\n",
       " 'atau',\n",
       " 'harus',\n",
       " 'datang',\n",
       " 'ke sana',\n",
       " 'siang',\n",
       " 'kak',\n",
       " 'mau',\n",
       " 'tanya',\n",
       " 'kalau',\n",
       " 'untuk',\n",
       " 'tes',\n",
       " 'pre',\n",
       " 'marital',\n",
       " 'apa',\n",
       " 'saja',\n",
       " 'iya',\n",
       " 'dan',\n",
       " 'biaya',\n",
       " 'nya',\n",
       " 'di',\n",
       " 'berapa',\n",
       " 'pak',\n",
       " 'bu',\n",
       " 'maaf',\n",
       " 'bisa',\n",
       " 'tanya',\n",
       " 'biaya',\n",
       " 'operasi',\n",
       " 'tidak',\n",
       " 'buat',\n",
       " 'operasi',\n",
       " 'tiroid',\n",
       " 'terima kasih',\n",
       " 'mau',\n",
       " 'tanya',\n",
       " 'kalau',\n",
       " 'biaya',\n",
       " 'treadmill',\n",
       " 'berapa',\n",
       " 'iya',\n",
       " 'saya',\n",
       " 'peserta',\n",
       " 'bpjs',\n",
       " 'apakah',\n",
       " 'bisa',\n",
       " 'ke',\n",
       " 'dokter',\n",
       " 'nia',\n",
       " 'hari',\n",
       " 'rabu',\n",
       " 'tanggal',\n",
       " '28',\n",
       " 'juni']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to change the slang words to standard words\n",
    "with open(r'D:\\Kerja\\Data\\Data Analyst\\NLP\\combined_slang_words.txt','r') as file:\n",
    "    slang_words=file.readlines()\n",
    "slang_words = ast.literal_eval(slang_words[0])\n",
    "\n",
    "word_tokens = word_tokenize(sentence)\n",
    "for i in range(len(word_tokens)):\n",
    "    if word_tokens[i] in slang_words.keys():\n",
    "        word_tokens[i] = slang_words[word_tokens[i]]\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['halo',\n",
       " 'pendaftaran',\n",
       " 'via',\n",
       " 'whatsapp',\n",
       " 'ke sana',\n",
       " 'siang',\n",
       " 'kak',\n",
       " 'tes',\n",
       " 'pre',\n",
       " 'marital',\n",
       " 'iya',\n",
       " 'biaya',\n",
       " 'nya',\n",
       " 'bu',\n",
       " 'maaf',\n",
       " 'biaya',\n",
       " 'operasi',\n",
       " 'operasi',\n",
       " 'tiroid',\n",
       " 'terima kasih',\n",
       " 'biaya',\n",
       " 'treadmill',\n",
       " 'iya',\n",
       " 'peserta',\n",
       " 'bpjs',\n",
       " 'dokter',\n",
       " 'nia',\n",
       " 'rabu',\n",
       " 'tanggal',\n",
       " '28',\n",
       " 'juni']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to erase the stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "list_of_words = [word for word in word_tokens if word.casefold() not in stop_words]\n",
    "list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
